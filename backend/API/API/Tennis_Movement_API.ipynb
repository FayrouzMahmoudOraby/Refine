{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ettdQYMfyE1P",
        "outputId": "317d6fd2-8d2b-4738-c10b-6ccba3b5fe25"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: fastapi in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (0.115.12)\n",
            "Requirement already satisfied: uvicorn in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (0.34.2)\n",
            "Requirement already satisfied: nest_asyncio in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (1.6.0)\n",
            "Requirement already satisfied: pyngrok in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (7.2.4)\n",
            "Requirement already satisfied: opencv-python in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (4.11.0.86)\n",
            "Requirement already satisfied: onnxruntime in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (1.21.1)\n",
            "Requirement already satisfied: tensorflow in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (2.19.0)\n",
            "Requirement already satisfied: starlette<0.47.0,>=0.40.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from fastapi) (0.46.2)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from fastapi) (2.11.3)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from fastapi) (4.13.2)\n",
            "Requirement already satisfied: click>=7.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from uvicorn) (8.1.8)\n",
            "Requirement already satisfied: h11>=0.8 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from uvicorn) (0.14.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from pyngrok) (6.0.2)\n",
            "Requirement already satisfied: numpy>=1.21.2 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from opencv-python) (2.1.3)\n",
            "Requirement already satisfied: coloredlogs in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from onnxruntime) (15.0.1)\n",
            "Requirement already satisfied: flatbuffers in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from onnxruntime) (25.2.10)\n",
            "Requirement already satisfied: packaging in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from onnxruntime) (25.0)\n",
            "Requirement already satisfied: protobuf in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from onnxruntime) (5.29.4)\n",
            "Requirement already satisfied: sympy in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from onnxruntime) (1.13.3)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (2.2.2)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (1.6.3)\n",
            "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (0.6.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (0.2.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (18.1.1)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (3.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (2.32.3)\n",
            "Requirement already satisfied: setuptools in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (65.5.0)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (1.17.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (3.0.1)\n",
            "Requirement already satisfied: wrapt>=1.11.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (1.17.2)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (1.71.0)\n",
            "Requirement already satisfied: tensorboard~=2.19.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (2.19.0)\n",
            "Requirement already satisfied: keras>=3.5.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (3.9.2)\n",
            "Requirement already satisfied: h5py>=3.11.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (3.13.0)\n",
            "Requirement already satisfied: ml-dtypes<1.0.0,>=0.5.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (0.5.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorflow) (0.31.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from astunparse>=1.6.0->tensorflow) (0.45.1)\n",
            "Requirement already satisfied: colorama in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from click>=7.0->uvicorn) (0.4.6)\n",
            "Requirement already satisfied: rich in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (14.0.0)\n",
            "Requirement already satisfied: namex in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.0.9)\n",
            "Requirement already satisfied: optree in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from keras>=3.5.0->tensorflow) (0.15.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (2.33.1)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,!=2.0.0,!=2.0.1,!=2.1.0,<3.0.0,>=1.7.4->fastapi) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from requests<3,>=2.21.0->tensorflow) (2025.1.31)\n",
            "Requirement already satisfied: anyio<5,>=3.6.2 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from starlette<0.47.0,>=0.40.0->fastapi) (4.9.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.8)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (0.7.2)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from tensorboard~=2.19.0->tensorflow) (3.1.3)\n",
            "Requirement already satisfied: humanfriendly>=9.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from coloredlogs->onnxruntime) (10.0)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from sympy->onnxruntime) (1.3.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from anyio<5,>=3.6.2->starlette<0.47.0,>=0.40.0->fastapi) (1.3.1)\n",
            "Requirement already satisfied: pyreadline3 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from humanfriendly>=9.1->coloredlogs->onnxruntime) (3.5.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard~=2.19.0->tensorflow) (3.0.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from rich->keras>=3.5.0->tensorflow) (2.19.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.2)\n",
            "Requirement already satisfied: python-multipart in c:\\users\\fayroz\\documents\\github\\refine\\.venv\\lib\\site-packages (0.0.20)\n",
            "Authtoken saved to configuration file: C:\\Users\\Fayroz\\AppData\\Local/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!pip install fastapi uvicorn nest_asyncio pyngrok opencv-python onnxruntime tensorflow\n",
        "!pip install python-multipart\n",
        "!ngrok config add-authtoken 2w632UmskfhkiCHNqk8koimwg08_89pfMfZsEGcJj2q56zHkD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "bohpHKK8yTkG"
      },
      "outputs": [],
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import os\n",
        "import json\n",
        "import shutil\n",
        "from fastapi import FastAPI, UploadFile\n",
        "from fastapi.responses import FileResponse, JSONResponse\n",
        "from tensorflow.keras.applications import InceptionV3\n",
        "from tensorflow.keras.applications.inception_v3 import preprocess_input\n",
        "from tensorflow.keras.models import load_model\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "import onnxruntime as ort\n",
        "import nest_asyncio\n",
        "from pyngrok import ngrok\n",
        "import uvicorn"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7TfYFkeTfW_j",
        "outputId": "eb9ccfe2-4053-4d9c-eef2-c05871286479"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
          ]
        }
      ],
      "source": [
        "app = FastAPI()\n",
        "\n",
        "# Load Models\n",
        "feature_extractor = InceptionV3(weights='imagenet', include_top=False, pooling='avg')\n",
        "action_model = load_model('tennis_action_model.h5')\n",
        "movenet_session = ort.InferenceSession('movenet_int8.onnx')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "27OOUW8lfZCt"
      },
      "outputs": [],
      "source": [
        "SEQUENCE_LENGTH = 10\n",
        "IMG_SIZE = (299, 299)\n",
        "\n",
        "labels = [\n",
        "    'backhand', 'backhand2hands', 'backhand_slice', 'backhand_volley',\n",
        "    'flat_service', 'forehand_flat', 'forehand_openstands', 'forehand_slice',\n",
        "    'forehand_volley', 'kick_service', 'slice_service', 'smash'\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "nVyHpTB1fkqu"
      },
      "outputs": [],
      "source": [
        "def extract_frames(video_file, max_frames=SEQUENCE_LENGTH):\n",
        "    cap = cv2.VideoCapture(video_file)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    step = max(1, total_frames // max_frames)\n",
        "    frames = []\n",
        "\n",
        "    for i in range(0, total_frames, step):\n",
        "        cap.set(cv2.CAP_PROP_POS_FRAMES, i)\n",
        "        ret, frame = cap.read()\n",
        "        if not ret:\n",
        "            break\n",
        "        frame = cv2.resize(frame, IMG_SIZE)\n",
        "        frame = preprocess_input(img_to_array(frame))\n",
        "        frames.append(frame)\n",
        "        if len(frames) == max_frames:\n",
        "            break\n",
        "    cap.release()\n",
        "    while len(frames) < max_frames:\n",
        "        frames.append(np.zeros_like(frames[0]))\n",
        "    return np.array(frames)\n",
        "\n",
        "def decode_prediction(pred):\n",
        "    return labels[np.argmax(pred)]\n",
        "\n",
        "def check_correctness(predicted_label):\n",
        "    return True  # Placeholder: All detected movements are correct\n",
        "\n",
        "def extract_joints_with_movenet(frame):\n",
        "    input_size = 192\n",
        "    resized_frame = cv2.resize(frame, (input_size, input_size))\n",
        "    input_image = np.expand_dims(resized_frame, axis=0).astype(np.float32) / 255.0  # Normalize\n",
        "\n",
        "    input_name = movenet_session.get_inputs()[0].name\n",
        "    output_name = movenet_session.get_outputs()[0].name\n",
        "\n",
        "    outputs = movenet_session.run([output_name], {input_name: input_image})\n",
        "    heatmaps = outputs[0][0]  # Shape: (48, 48, 17)\n",
        "\n",
        "    joint_names = [\n",
        "        \"nose\", \"left_eye\", \"right_eye\", \"left_ear\", \"right_ear\",\n",
        "        \"left_shoulder\", \"right_shoulder\", \"left_elbow\", \"right_elbow\",\n",
        "        \"left_wrist\", \"right_wrist\", \"left_hip\", \"right_hip\",\n",
        "        \"left_knee\", \"right_knee\", \"left_ankle\", \"right_ankle\"\n",
        "    ]\n",
        "\n",
        "    normalized_keypoints = []\n",
        "    for i in range(heatmaps.shape[-1]):\n",
        "        heatmap = heatmaps[:, :, i]\n",
        "        y, x = np.unravel_index(np.argmax(heatmap), heatmap.shape)\n",
        "\n",
        "        x_normalized = x / heatmaps.shape[1]\n",
        "        y_normalized = y / heatmaps.shape[0]\n",
        "\n",
        "        normalized_keypoints.append({\n",
        "            \"joint\": joint_names[i],\n",
        "            \"x\": float(round(x_normalized, 2)),\n",
        "            \"y\": float(round(y_normalized, 2))\n",
        "        })\n",
        "\n",
        "    return normalized_keypoints\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "L-gMlS4ifpSb"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "from fastapi import FastAPI, UploadFile\n",
        "from fastapi.responses import FileResponse, JSONResponse\n",
        "import shutil\n",
        "import json\n",
        "import cv2\n",
        "import numpy as np\n",
        "\n",
        "app = FastAPI()\n",
        "\n",
        "# Define a writable directory for temporary files\n",
        "OUTPUT_DIR = \"./outputs\"\n",
        "os.makedirs(OUTPUT_DIR, exist_ok=True)  # Create the directory if it doesn't exist\n",
        "\n",
        "@app.post(\"/analyze_video/\")\n",
        "async def analyze_video(file: UploadFile):\n",
        "    try:\n",
        "        # Save the uploaded video to a temporary file\n",
        "        temp_video_path = os.path.join(OUTPUT_DIR, \"temp_video.mp4\")\n",
        "        with open(temp_video_path, \"wb\") as buffer:\n",
        "            shutil.copyfileobj(file.file, buffer)\n",
        "\n",
        "        # Extract frames from the video\n",
        "        frames = extract_frames(temp_video_path)  # Shape: (10, 299, 299, 3)\n",
        "\n",
        "        # Extract features from frames\n",
        "        sequence_features = []\n",
        "        for frame in frames:\n",
        "            frame_exp = np.expand_dims(frame, axis=0)\n",
        "            features = feature_extractor.predict(frame_exp, verbose=0)\n",
        "            sequence_features.append(features[0])\n",
        "\n",
        "        sequence_features = np.array(sequence_features)  # Shape: (10, 2048)\n",
        "        sequence_features = np.expand_dims(sequence_features, axis=0)  # Shape: (1, 10, 2048)\n",
        "\n",
        "        # Predict the action\n",
        "        prediction = action_model.predict(sequence_features)\n",
        "        predicted_label = decode_prediction(prediction)\n",
        "\n",
        "        # Extract joints from the last frame\n",
        "        raw_frame = cv2.VideoCapture(temp_video_path)\n",
        "        raw_frame.set(cv2.CAP_PROP_POS_FRAMES, int(raw_frame.get(cv2.CAP_PROP_FRAME_COUNT)) - 1)\n",
        "        ret, last_frame = raw_frame.read()\n",
        "        raw_frame.release()\n",
        "\n",
        "        joints = extract_joints_with_movenet(last_frame)\n",
        "\n",
        "        # Prepare the response\n",
        "        response = {\n",
        "            \"player\": {\n",
        "                \"isCorrect\": check_correctness(predicted_label),\n",
        "                \"movement\": predicted_label,\n",
        "                \"prediction\": predicted_label,\n",
        "                \"joints\": joints\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Save the response to a JSON file\n",
        "        output_file_path = os.path.join(OUTPUT_DIR, \"player_analysis.json\")\n",
        "        with open(output_file_path, \"w\") as outfile:\n",
        "            json.dump(response, outfile, indent=2)\n",
        "\n",
        "        # Return the JSON file as a response\n",
        "        return FileResponse(path=output_file_path, media_type='application/json', filename=\"player_analysis.json\")\n",
        "\n",
        "    except Exception as e:\n",
        "        return JSONResponse(status_code=500, content={\"error\": str(e)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Authtoken saved to configuration file: C:\\Users\\Fayroz\\AppData\\Local/ngrok/ngrok.yml\n"
          ]
        }
      ],
      "source": [
        "!ngrok config add-authtoken 2w632UmskfhkiCHNqk8koimwg08_89pfMfZsEGcJj2q56zHkD"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1Y0GVJrtwjL",
        "outputId": "dc1d4be3-5615-4b52-81cd-b4d52c39091e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "ERROR:pyngrok.process.ngrok:t=2025-04-29T20:04:17+0300 lvl=eror msg=\"unable to evaluate ngrok agent binary path for symlinks\" obj=tunnels.session err=\"CreateFile C:\\\\Users\\\\Fayroz\\\\AppData\\\\Local\\\\ngrok\\\\ngrok.exe: The system cannot find the file specified.\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "API is running at: NgrokTunnel: \"https://a0dc-41-238-124-8.ngrok-free.app\" -> \"http://localhost:8000\"/docs\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:     Started server process [27720]\n",
            "INFO:     Waiting for application startup.\n",
            "INFO:     Application startup complete.\n",
            "INFO:     Uvicorn running on http://0.0.0.0:8000 (Press CTRL+C to quit)\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 868ms/step\n",
            "INFO:     41.238.124.8:0 - \"POST /analyze_video/ HTTP/1.1\" 200 OK\n"
          ]
        }
      ],
      "source": [
        "nest_asyncio.apply()\n",
        "\n",
        "public_url = ngrok.connect(8000)\n",
        "print(f\"API is running at: {public_url}/docs\")\n",
        "\n",
        "uvicorn.run(app, host=\"0.0.0.0\", port=8000)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
